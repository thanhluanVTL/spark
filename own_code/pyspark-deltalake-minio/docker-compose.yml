version: '2'

services:
  spark:
    build: ./spark
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080'
      - '7077:7077'
    volumes:
      - ./data:/data
      - ./spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
  spark-worker:
    build: ./spark
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./data:/data
  # jupyter:
  #   build: ./jupyter/
  #   environment:
  #     - S3_ENDPOINT=http://minio:9000
  #     - S3_BUCKET=test
  #     - S3_ACCESS_KEY=sparkaccesskey
  #     - S3_SECRET_KEY=sparksupersecretkey
  #   ports: 
  #     - 8888:8888
  #   volumes:
  #     - ./data:/data
  #     - ./jupyter/notebooks/:/notebooks/

  client:
    build: ./client/
    environment:
      - S3_ENDPOINT=http://minio:9000
      - S3_BUCKET=test
      - S3_ACCESS_KEY=sparkaccesskey
      - S3_SECRET_KEY=sparksupersecretkey
    ports: 
      - 8888:8888
    volumes:
      - ./data:/data
      - ./client/code/:/home/code/
    stdin_open: true # docker run -i
    tty: true        # docker run -t

  minio:
    image: quay.io/minio/minio
    command: ["server", "/data", "--console-address", ":9090"]
    environment:
      - MINIO_ROOT_USER=minio
      - MINIO_ROOT_PASSWORD=minio123
    volumes:
      - minio-data:/data
    ports:
      - 9090:9090
      - 9000:9000
  minio-init:
    build: ./minio # MinioClient image; use it to make buckets and perform any other tasks on startup
    depends_on:
      - minio
      
volumes:
  minio-data:
